import osimport timeimport torchfrom torch import nnfrom einops import rearrangefrom Train_and_Eval.device import get_device# @torch.compile(mode="reduce-overhead")class AllinMamba(nn.Module):    def __init__(self, input_channels, num_classes, patch_size, feature_dim=128, depth=1, mlp_dim=64, dropout=0.37,                 d_state=16, expand=8, mode=2, root_mamba=False):        super().__init__()        self.dim = 2        self.feature_dim = feature_dim        self.depth = depth        self.patch_size = patch_size        self.dropout = dropout        self.scan_length = patch_size // 2 * 4 + 4        self.input_channels = input_channels        self.chunk_size = 4        self.conv3d_sep = nn.Sequential(            nn.Conv3d(in_channels=1, out_channels=1, kernel_size=(7, 3, 3), padding=(3, 1, 1), groups=1),            nn.BatchNorm3d(1),            nn.SiLU(),            nn.Conv3d(in_channels=1, out_channels=8, kernel_size=1),            nn.BatchNorm3d(8),            nn.SiLU()        )        self.conv2d_sep = nn.Sequential(            nn.Conv2d(in_channels=input_channels * 8, out_channels=input_channels * 8, kernel_size=3, padding=1,                      groups=input_channels * 8),            nn.BatchNorm2d(input_channels * 8),            nn.ReLU(),            nn.Conv2d(in_channels=input_channels * 8, out_channels=feature_dim, kernel_size=1),            nn.BatchNorm2d(feature_dim),            nn.ReLU()        )        self.conv2d_dim = nn.Sequential(            nn.Conv2d(in_channels=input_channels, out_channels=feature_dim, kernel_size=1),            nn.ReLU()        )        self.linear = nn.Linear(input_channels, feature_dim)        self.fusion_gate = nn.Sequential(            nn.Linear(self.feature_dim * 2, 2),            nn.Softmax(dim=1)        )        self.classifier = nn.Sequential(            nn.Linear(feature_dim, mlp_dim),            nn.ReLU(),            nn.Dropout(dropout),            nn.Linear(mlp_dim, num_classes),            nn.BatchNorm1d(num_classes)        )        if root_mamba:            try:                from mamba_ssm import Mamba2, Mamba as Mamba1            except ImportError:                from src.MambaBase.Mamba1 import Mamba1                from src.MambaBase.Mamba2 import Mamba2        else:            from src.MambaBase.Mamba1 import Mamba1            from src.MambaBase.Mamba2 import Mamba2        # d_conv = 2/4        if mode == 1:            self.MambaLayer1 = Mamba1(                d_model=feature_dim,                d_state=d_state,                expand=expand            )            self.MambaLayer2 = Mamba1(                d_model=self.scan_length,                d_state=d_state,                expand=expand            )            self.MambaLayer3 = Mamba1(                d_model=self.input_channels,                d_state=d_state,                expand=expand            )        else:            # head 数量 = expand * d_model/ headdim。            self.MambaLayer1 = Mamba2(                d_model=feature_dim,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=self.chunk_size            )            self.MambaLayer2 = Mamba2(                d_model=self.scan_length,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=self.chunk_size            )            self.MambaLayer3 = Mamba2(                d_model=self.input_channels,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=1            )    @staticmethod    def prepare_data_RCS(x):        """        Args:            x: 原始输入数据 (B, C, H, W)        Returns:            标准化的输入数据 (B, C, H, W)        """        B, C, H, W = x.shape        x_reshaped = x.permute(0, 2, 3, 1).reshape(-1, C)        mean = x_reshaped.mean(dim=0, keepdim=True)        std = x_reshaped.std(dim=0, keepdim=True) + 1e-6        x_normalized = (x_reshaped - mean) / std        x_out = x_normalized.reshape(B, H, W, C).permute(0, 3, 1, 2)        x_out = x_out * torch.rsqrt(x_out.pow(2).mean(dim=(1, 2, 3), keepdim=True) + 1e-5)        return nn.SiLU()(x_out)    @staticmethod    def prepare_data_standard(x):        """        对输入张量进行标准化处理        Args:            x: 输入张量 (B, C, H, W)        Returns:            标准化后的张量 (B, C, H, W)        """        # 计算每个通道的均值和标准差，保持维度便于广播        mean = x.mean(dim=(0, 2, 3), keepdim=True)        std = x.std(dim=(0, 2, 3), keepdim=True) + 1e-6  # 防止除零        # 标准化操作        x_normalized = (x - mean) / std        return x_normalized    @staticmethod    def prepare_data_minmax(x):        """        对输入张量进行 Min-Max 归一化处理        Args:            x: 输入张量 (B, C, H, W)        Returns:            归一化后的张量 (B, C, H, W)，数值范围在 [0, 1]        """        # 计算每个通道的最小值和最大值        min_val = x.amin(dim=(0, 2, 3), keepdim=True)        max_val = x.amax(dim=(0, 2, 3), keepdim=True)        # Min-Max 归一化操作        x_normalized = (x - min_val) / (max_val - min_val + 1e-6)        return x_normalized    def feature_extraction_residual(self, x):        """        Residual 实现：使用 conv3d_sep + conv2d_sep 提取特征，        再通过 conv2d_dim 对原始输入进行残差映射，然后将二者相加。        输入: x，形状 (B, C, H, W)        输出: 特征张量, 形状 (B, feature_dim, H, W)        """        residual_x = x        x_out = self.conv3d_sep(x.unsqueeze(1))  # (B, 1, C, H, W) -> (B, t, c, H, W)        x_out = rearrange(x_out, 'b t c h w -> b (t c) h w')        x_out = self.conv2d_sep(x_out)        residual_x = self.conv2d_dim(residual_x)        return x_out + residual_x    def feature_extraction_no_conv3d(self, x):        """        消融实现 1：去除 conv3d_sep 部分，仅使用 conv2d_sep 提取特征，        为了保证 conv2d_sep 的输入通道数匹配，这里简单采用 repeat 操作扩充通道数。        输入: x，形状 (B, C, H, W)        输出: 特征张量, 形状 (B, feature_dim, H, W)        """        residual_x = x        # 假设 conv2d_sep 期望的通道数为 input_channels * 8        x_expanded = x.repeat(1, 8, 1, 1)  # (B, C*8, H, W)        x_out = self.conv2d_sep(x_expanded)        residual_x = self.conv2d_dim(residual_x)        return x_out + residual_x    def feature_extraction_baseline(self, x):        """        Baseline 实现：使用 conv3d_sep + conv2d_sep 提取特征，        输入: x，形状 (B, C, H, W)        输出: 特征张量, 形状 (B, feature_dim, H, W)        """        x_out = self.conv3d_sep(x.unsqueeze(1))        x_out = rearrange(x_out, 'b t c h w -> b (t c) h w')        x_out = self.conv2d_sep(x_out)        return x_out    def feature_extraction_no_conv2d_sep(self, x):        """        消融实现：移除 conv2d_sep 分支，仅使用 conv3d_sep 提取特征，        并使用一个 1×1 卷积将通道数映射到 feature_dim，再加上 conv2d_dim 的残差连接。        输入:            x: 张量, 形状 (B, C, H, W)        输出:            特征张量, 形状 (B, feature_dim, H, W)        """        # 计算残差分支：使用 conv2d_dim 将原始输入映射到目标特征维度        residual_x = self.conv2d_dim(x)        # 通过 conv3d_sep 提取特征，先对输入增加维度        x_out = self.conv3d_sep(x.unsqueeze(1))  # 输出形状 (B, t, c, H, W)        # 将 (t, c) 两个维度合并到通道维度        x_out = rearrange(x_out, 'b t c h w -> b (t c) h w')        # 为了使 x_out 通道数与 residual_x 保持一致，        # 使用一个 1×1 卷积进行通道映射。这里建议在 __init__ 中定义 self.conv_map，        # 若没有定义，则临时构造一个（注意：临时构造的卷积不会参与训练，仅用于实验对比）。        if hasattr(self, 'conv_map'):            x_out = self.conv_map(x_out)        else:            conv_map = nn.Conv2d(x_out.size(1), residual_x.size(1), kernel_size=1).to(x.device)            x_out = conv_map(x_out)        return x_out + residual_x    @staticmethod    def get_weights_mean(length, device):        weights = torch.ones(length, device=device) / length        return weights    @staticmethod    def get_weights_cos(length, device='cuda'):        center = length // 2        weights = torch.exp(-0.5 * ((torch.arange(length) - center) / (center / 2)) ** 2).to(device)        return weights    @staticmethod    def get_weights_triangular(length, device='cuda'):        if length == 1:            return torch.ones(1, device=device)        # 使用 (length - 1) / 2 得到中心位置（可能为浮点数）        center = (length - 1) / 2.0        indices = torch.arange(length, device=device, dtype=torch.float32)        # 计算距离中心的归一化绝对距离，并取 1 - distance 作为权重        weights = 1 - torch.abs(indices - center) / center        # 归一化权重使其总和为 1        weights = weights / weights.sum()        return weights    @staticmethod    def get_weights_new(length, device='cuda', sigma=1.0):        center = length // 2        indices = torch.arange(length, device=device)        squared_distances = (indices - center) ** 2 + center ** 2        decay_factor = -0.5 / (sigma ** 2)        weights = torch.exp(decay_factor * squared_distances)        weights = weights / weights.sum()        return weights    def smallScan(self, x):        """        Args:            x: 输入张量, shape=(B, hidden_dim, H, W)        Returns:            螺旋扫描后的特征, shape=(B, scan_length, hidden_dim)        """        center = self.patch_size // 2        x_scan = torch.zeros((x.shape[0], x.shape[1], self.scan_length), device=x.device)        x_scan[:, :, 3] = torch.zeros((x.shape[0], x.shape[1]), device=x.device)        x_scan[:, :, 2] = torch.zeros((x.shape[0], x.shape[1]), device=x.device)        x_scan[:, :, 1] = torch.zeros((x.shape[0], x.shape[1]), device=x.device)        x_scan[:, :, 0] = x[:, :, center, center]        for i in range(center):            weights = self.get_weights(2 * i + 3, device=x.device)            # 顶行            x_slice = x[:, :, center - i - 1, center - i - 1:center + i + 2]            x_scan[:, :, i * 4 + 4] = (x_slice * weights.view(1, 1, -1)).sum(dim=-1) / weights.sum()            # 右列            x_slice = x[:, :, center - i - 1:center + i + 2, center + i + 1]            x_scan[:, :, i * 4 + 5] = (x_slice * weights.view(1, 1, -1)).sum(dim=-1) / weights.sum()            # 底行            x_slice = x[:, :, center + i + 1, center - i - 1:center + i + 2]            x_scan[:, :, i * 4 + 6] = (x_slice * weights.view(1, 1, -1)).sum(dim=-1) / weights.sum()            # 左列            x_slice = x[:, :, center - i - 1:center + i + 2, center - i - 1]            x_scan[:, :, i * 4 + 7] = (x_slice * weights.view(1, 1, -1)).sum(dim=-1) / weights.sum()        return x_scan.transpose(1, 2)    def MambaBlock(self, x):        """        Args:            x: 输入张量, shape=(B, scan_length, hidden_dim)        Returns:            经过MambaBlock处理后的张量, shape=(B, scan_length, hidden_dim)        """        for _ in range(self.depth):            x = self.MambaLayer1(x)            x = x.transpose(1, 2)            x = self.MambaLayer2(x)            x = x.transpose(1, 2)        return x    def forward(self, x):        x = self.prepare_data(x)        x1 = self.spatial_route(x)        x2 = self.spectral_route(x)        x1 = self.fusion_way(x1, x2)        combined_features = torch.cat([x1, x2], dim=1)        weights = self.fusion_gate(combined_features)        x = weights[:, 0:1] * x1 + weights[:, 1:2] * x2        x = self.classifier(x)        return x    def spatial_route(self, x):        x = self.Feature_extraction(x)        x = self.smallScan(x)        x = self.MambaBlock(x)        x = x[:, 0:4].mean(dim=1)        return x    def spectral_route(self, x):        center_pixel = x[:, :, self.patch_size // 2, self.patch_size // 2]        center_pixel = center_pixel.unsqueeze(1)        for _ in range(self.depth):            center_pixel = self.MambaLayer3(center_pixel)        center_pixel = self.linear(center_pixel.squeeze(1))        return center_pixel    @staticmethod    def fusion_way1(x1, x2):        # 计算余弦相似度        cos_sim = nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8)        gate = (cos_sim + 1) / 2        x1 = gate.unsqueeze(1) * x1        return x1    @staticmethod    def fusion_way_baseline(x1, x2):        gate = torch.sigmoid(x2)        x1 = gate * x1        return x1    def fusion_way(self, x1, x2):        return self.fusion_way_baseline(x1, x2)        # return self.fusion_way1(x1, x2)        # return x1    def prepare_data(self, x):        return self.prepare_data_standard(x)        # return self.prepare_data_minmax(x)        # return self.prepare_data_RCS(x)        # return x    def get_weights(self, length, device='cuda'):        # return self.get_weights_cos(length, device)        # return self.get_weights_mean(length, device)        # return self.get_weights_triangular(length, device)        return self.get_weights_new(length, device)    def Feature_extraction(self, x):        return self.feature_extraction_baseline(x)        # return self.feature_extraction_no_conv3d(x)        # return self.feature_extraction_no_conv2d_sep(x)        # return self.feature_extraction_residual(x)if __name__ == "__main__":    input_channels = 80    num_classes = 10    patch_size = 9    batch_size = 4    depth = 1    # Model initialization and device placement    model = AllinMamba(input_channels=input_channels, num_classes=num_classes, patch_size=patch_size, depth=depth)    device = get_device()    print(f"Using device: {device}")    model = model.to(device)    # Inference test    x = torch.randn(batch_size, input_channels, patch_size, patch_size).to(device)    # Measure inference time and memory    start_epoch = time.time()    with torch.no_grad():  # Inference mode        out = model(x)    inference_time = time.time() - start_epoch    print(f'Inference time: {inference_time:.4f} seconds')    print(f'Output shape: {out.shape}')