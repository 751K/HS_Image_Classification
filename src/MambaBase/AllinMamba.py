import timeimport torchfrom torch import nnfrom einops import rearrangefrom Train_and_Eval.device import get_devicefrom src.MambaBase.Mamba1 import Mamba1from src.MambaBase.Mamba2 import Mamba2# @torch.compile(mode="reduce-overhead")class AllinMamba(nn.Module):    def __init__(self, input_channels, num_classes, patch_size, feature_dim=128, depth=1, mlp_dim=64, dropout=0.25,                 d_state=16, expand=8, mode=2, scan_way=0):        super().__init__()        self.dim = 2        self.feature_dim = feature_dim        self.depth = depth        self.patch_size = patch_size        self.dropout = dropout        if scan_way == 0:            self.scan_length = patch_size // 2 * 4 + 4            self.cls_tokens = nn.Parameter(torch.randn(1, self.feature_dim, 1) * 0.02)        else:            self.scan_length = patch_size * patch_size + 3            self.cls_tokens = nn.Parameter(torch.randn(1, self.feature_dim, 3) * 0.02)        self.scan_way = scan_way        self.input_channels = input_channels        self.chunk_size = 4        self.conv3d_sep = nn.Sequential(            nn.Conv3d(in_channels=1, out_channels=1, kernel_size=(7, 3, 3), padding=(3, 1, 1), groups=1),            nn.BatchNorm3d(1),            nn.SiLU(),            nn.Conv3d(in_channels=1, out_channels=8, kernel_size=1),            nn.BatchNorm3d(8),            nn.SiLU()        )        self.conv2d_sep = nn.Sequential(            nn.Conv2d(in_channels=input_channels * 8, out_channels=input_channels * 8, kernel_size=3, padding=1,                      groups=input_channels * 8),            nn.BatchNorm2d(input_channels * 8),            nn.SiLU(),            nn.Conv2d(in_channels=input_channels * 8, out_channels=feature_dim, kernel_size=1),            nn.BatchNorm2d(feature_dim),            nn.SiLU()        )        self.linear = nn.Linear(input_channels, feature_dim)        self.fusion_gate = nn.Sequential(            nn.Linear(self.feature_dim * 2, 64),            nn.BatchNorm1d(64),            nn.ReLU(),            nn.Dropout(dropout / 2),            nn.Linear(64, 2),            nn.Softmax(dim=1)        )        self.classifier = nn.Sequential(            nn.Linear(feature_dim, mlp_dim),            nn.BatchNorm1d(mlp_dim),            nn.ReLU(),            nn.Dropout(dropout),            nn.Linear(mlp_dim, num_classes)        )        # d_conv = 2/4        if mode == 1:            self.MambaLayer1 = Mamba1(                d_model=feature_dim,                d_state=d_state,                expand=expand            )            self.MambaLayer2 = Mamba1(                d_model=self.scan_length,                d_state=d_state,                expand=expand            )            self.MambaLayer3 = Mamba1(                d_model=self.input_channels,                d_state=d_state,                expand=expand            )        else:            # head 数量 = expand * d_model/ headdim。            self.MambaLayer1 = Mamba2(                d_model=feature_dim,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=self.chunk_size            )            self.MambaLayer2 = Mamba2(                d_model=self.scan_length,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=self.chunk_size            )            self.MambaLayer3 = Mamba2(                d_model=self.input_channels,                d_state=d_state,                headdim=16,                expand=expand,                chunk_size=1            )        self._weights_cache = {}    @staticmethod    def prepare_data(x):        """        对输入张量进行标准化处理并重排通道顺序        Args:            x: 输入张量 (B, C, H, W)        Returns:            标准化和通道重排后的张量 (B, C, H, W)        """        # 计算每个通道的均值和标准差，保持维度便于广播        mean = x.mean(dim=(0, 2, 3), keepdim=True)        std = x.std(dim=(0, 2, 3), keepdim=True) + 1e-6  # 防止除零        # 标准化操作        x_normalized = (x - mean) / std        # 通道重排：1,5,9,..., 2,6,10,..., 3,7,11,..., 4,8,12,...        channels = x_normalized.shape[1]        indices = torch.cat([            torch.arange(0, channels, 4, device=x.device),  # 对应编号1,5,9,...            torch.arange(1, channels, 4, device=x.device),  # 对应编号2,6,10,...            torch.arange(2, channels, 4, device=x.device),  # 对应编号3,7,11,...            torch.arange(3, channels, 4, device=x.device),  # 对应编号4,8,12,...        ])        # 确保索引不超出范围        indices = indices[indices < channels]        # 使用索引重排通道        x_reordered = x_normalized[:, indices, :, :]        return x_reordered    def feature_extraction(self, x):        """        使用 conv3d_sep + conv2d_sep 提取特征，        Args:            x: 输入张量 (B, C, H, W)        Returns:            特征张量：形状 (B, feature_dim, H, W)        """        x_out = self.conv3d_sep(x.unsqueeze(1))        x_out = rearrange(x_out, 'b t c h w -> b (t c) h w')        x_out = self.conv2d_sep(x_out)        return x_out    @staticmethod    def get_weights(length, device='cuda', sigma=1.0, cache=None):        if cache is not None and length in cache:            return cache[length]        center = length // 2        indices = torch.arange(length, device=device)        squared_distances = (indices - center) ** 2 + center ** 2        decay_factor = -0.5 / (sigma ** 2)        weights = torch.exp(decay_factor * squared_distances)        weights = weights / weights.sum()        if cache is not None:            cache[length] = weights        return weights    def weight_scan(self, x):        """优化版螺旋扫描函数"""        center = self.patch_size // 2        batch_size, channels = x.shape[0], x.shape[1]        x_scan = torch.zeros((batch_size, channels, self.scan_length), device=x.device)        x_scan[:, :, 0:1] = self.cls_tokens.expand(batch_size, -1, -1)        x_scan[:, :, 1:4] = x[:, :, center, center].unsqueeze(-1).expand(-1, -1, 3)        # 预计算权重        weights_cache = {}        for i in range(center):            size = 2 * i + 3            if size not in weights_cache:                weights_cache[size] = self.get_weights(size, device=x.device)            weights = weights_cache[size]            weights_sum = weights.sum()  # 只计算一次            # 顶行、右列、底行、左列的扫描和加权平均            slices = [                x[:, :, center - i - 1, center - i - 1:center + i + 2],  # 顶行                x[:, :, center - i - 1:center + i + 2, center + i + 1],  # 右列                x[:, :, center + i + 1, center - i - 1:center + i + 2],  # 底行                x[:, :, center - i - 1:center + i + 2, center - i - 1]  # 左列            ]            for j, slice_data in enumerate(slices):                x_scan[:, :, i * 4 + 4 + j] = (slice_data * weights.view(1, 1, -1)).sum(dim=-1) / weights_sum        return x_scan.transpose(1, 2)    def similarity_scan(self, x):        center = self.patch_size // 2        batch_size, channels = x.shape[0], x.shape[1]        # 初始化结果张量        x_scan = torch.zeros((batch_size, channels, self.scan_length), device=x.device)        # 设置CLS tokens和中心像素        x_scan[:, :, 0:3] = self.cls_tokens.expand(batch_size, -1, -1)        center_features = x[:, :, center, center]        x_scan[:, :, 3] = center_features        # 创建所有坐标点并提取特征        coords = torch.stack(torch.meshgrid(            torch.arange(self.patch_size, device=x.device),            torch.arange(self.patch_size, device=x.device),            indexing='ij'        ), dim=-1).reshape(-1, 2)        # 移除中心点        center_mask = ~((coords[:, 0] == center) & (coords[:, 1] == center))        coords = coords[center_mask]        # 批量提取特征并计算相似度        features = x[:, :, coords[:, 0], coords[:, 1]].permute(2, 0, 1)  # (N, B, C)        norm_center = torch.nn.functional.normalize(center_features, dim=1)        norm_features = torch.nn.functional.normalize(features.permute(1, 2, 0), dim=1)  # (B, C, N)        similarities = torch.bmm(norm_center.unsqueeze(1), norm_features).squeeze(1)  # (B, N)        # 计算平均相似度并排序        mean_similarities = similarities.mean(dim=0)        _, indices = torch.sort(mean_similarities, descending=True)        # 填充结果        remaining = min(self.scan_length - 4, len(indices))        sorted_coords = coords[indices[:remaining]]        for i in range(remaining):            h, w = sorted_coords[i]            x_scan[:, :, i + 4] = x[:, :, h, w]        return x_scan.transpose(1, 2)    def radial_similarity_scan(self, x):        """        结合径向扫描和余弦相似度的扫描函数 - 按半径扫描但同一半径内按相似度排序        Args:            x: 输入张量, shape=(B, hidden_dim, H, W)        Returns:            扫描后的特征, shape=(B, scan_length, hidden_dim)        """        center = self.patch_size // 2        batch_size, channels = x.shape[0], x.shape[1]        # 初始化结果张量        x_scan = torch.zeros((batch_size, channels, self.scan_length), device=x.device)        # 设置CLS tokens        x_scan[:, :, 0:3] = self.cls_tokens.expand(batch_size, -1, -1)        # 获取中心像素特征        center_features = x[:, :, center, center]  # [batch_size, channels]        x_scan[:, :, 3] = center_features        # 径向扫描        idx = 4        max_radius = max(center, self.patch_size - center - 1)        # 按半径从小到大扫描        for r in range(1, max_radius + 1):            radius_points = []            # 收集这个半径上的所有点            for i in range(-r, r + 1):                # 上边和下边                if -r <= center + i < self.patch_size and 0 <= center - r < self.patch_size:                    radius_points.append((center + i, center - r))                if -r <= center + i < self.patch_size and 0 <= center + r < self.patch_size:                    radius_points.append((center + i, center + r))                # 左边和右边(避免角点重复)                if -r < i < r:                    if 0 <= center - i < self.patch_size and 0 <= center - r < self.patch_size:                        radius_points.append((center - i, center - r))                    if 0 <= center - i < self.patch_size and 0 <= center + r < self.patch_size:                        radius_points.append((center - i, center + r))            # 计算该半径上所有点与中心的相似度并排序            similarities = []            for i, j in radius_points:                pixel_features = x[:, :, i, j]                sim = torch.nn.functional.cosine_similarity(pixel_features, center_features, dim=1).mean().item()                similarities.append((i, j, sim))            # 按相似度降序排序            similarities.sort(key=lambda x: x[2], reverse=True)            # 将排序后的点添加到结果中            for i, j, _ in similarities:                if idx < self.scan_length:                    x_scan[:, :, idx] = x[:, :, i, j]                    idx += 1        return x_scan.transpose(1, 2)    def radial_scan(self, x):        """        径向扫描函数 - 从中心点开始，按同心圆方式向外扫描        Args:            x: 输入张量, shape=(B, hidden_dim, H, W)        Returns:            扫描后的特征, shape=(B, scan_length, hidden_dim)        """        center = self.patch_size // 2        batch_size, channels = x.shape[0], x.shape[1]        # 初始化结果张量        x_scan = torch.zeros((batch_size, channels, self.scan_length), device=x.device)        # 设置CLS tokens        x_scan[:, :, 0:3] = self.cls_tokens.expand(batch_size, -1, -1)        # 中心点        x_scan[:, :, 3] = x[:, :, center, center]        # 径向扫描        idx = 4        max_radius = max(center, self.patch_size - center - 1)        # 按半径从小到大扫描        for r in range(1, max_radius + 1):            # 计算这个半径上的所有点            points = []            # 上、右、下、左四个方向的点            for i in range(-r, r + 1):                # 上边和下边                if -r <= center + i < self.patch_size and 0 <= center - r < self.patch_size:                    points.append((center + i, center - r))                if -r <= center + i < self.patch_size and 0 <= center + r < self.patch_size:                    points.append((center + i, center + r))                # 左边和右边(避免角点重复)                if -r < i < r:                    if 0 <= center - i < self.patch_size and 0 <= center - r < self.patch_size:                        points.append((center - i, center - r))                    if 0 <= center - i < self.patch_size and 0 <= center + r < self.patch_size:                        points.append((center - i, center + r))            # 添加点到结果中            for i, j in points:                if idx < self.scan_length and 0 <= i < self.patch_size and 0 <= j < self.patch_size:                    x_scan[:, :, idx] = x[:, :, i, j]                    idx += 1        return x_scan.transpose(1, 2)    def MambaBlock(self, x):        """        Args:            x: 输入张量, shape=(B, scan_length, hidden_dim)        Returns:            经过MambaBlock处理后的张量, shape=(B, scan_length, hidden_dim)        """        x = self.MambaLayer1(x)        x_t = x.transpose(1, 2)        x = self.MambaLayer2(x_t)        # 如果深度大于1，继续处理剩余层        if self.depth > 1:            x_t = x.transpose(1, 2)  # 恢复原始维度顺序            for _ in range(1, self.depth):                x_t = self.MambaLayer1(x_t)                x = x_t.transpose(1, 2)                x = self.MambaLayer2(x)                if _ < self.depth - 1:  # 除了最后一次，都需要恢复维度顺序                    x_t = x.transpose(1, 2)        return x.transpose(1, 2)    def scan(self, x):        if self.scan_way == 0:            x = self.weight_scan(x)        elif self.scan_way == 1:            x = self.radial_scan(x)        elif self.scan_way == 2:            x = self.similarity_scan(x)        elif self.scan_way == 3:            x = self.radial_similarity_scan(x)        else:            raise ValueError("Invalid scan way. Choose scan_way: 0, 1, 2, or 3.")        return x    def spatial_route(self, x):        x = self.feature_extraction(x)        x = self.scan(x)        x = self.MambaBlock(x)        x = x[:, 0:4].mean(dim=1)        return x    def spectral_route(self, x):        center_pixel = x[:, :, self.patch_size // 2, self.patch_size // 2]        center_pixel = center_pixel.unsqueeze(1)        for _ in range(self.depth):            center_pixel = self.MambaLayer3(center_pixel)        center_pixel = self.linear(center_pixel.squeeze(1))        return center_pixel    @staticmethod    def fusion(x1, x2):        gate = torch.sigmoid(x2)        x1 = gate * x1        return x1    def forward(self, x):        x = self.prepare_data(x)        x1 = self.spatial_route(x)        x2 = self.spectral_route(x)        x1 = self.fusion(x1, x2)        combined_features = torch.cat([x1, x2], dim=1)        weights = self.fusion_gate(combined_features)        x = weights[:, 0:1] * x1 + weights[:, 1:2] * x2        x = self.classifier(x)        return xif __name__ == "__main__":    # 配置    input_channels = 80    num_classes = 10    patch_size = 9    batch_sizes = [2, 32, 128]  # 测试不同批大小    depth = 1    # 初始化模型    model = AllinMamba(        input_channels=input_channels,        num_classes=num_classes,        patch_size=patch_size,        depth=depth    )    device = get_device()    print(f"Using device: {device}")    model = model.to(device)    # 性能测试    for batch_size in batch_sizes:        # 预热        for _ in range(10):            with torch.no_grad():                x = torch.randn(batch_size, input_channels, patch_size, patch_size).to(device)                _ = model(x)        # 计时        start_time = time.time()        for _ in range(100):            with torch.no_grad():                x = torch.randn(batch_size, input_channels, patch_size, patch_size).to(device)                out = model(x)        inference_time = (time.time() - start_time) / 100        print(f'Batch size: {batch_size}, inference time: {inference_time:.4f} s/batch')        print(f'Throughput: {batch_size / inference_time:.2f} samples/sec')